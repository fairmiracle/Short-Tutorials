---
title: "Towards High Performance Computing Programming"
author: "Dong Li"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Motivation

I always want to make my program faster. During the past years I learned some tips on high performance computing programming, but they are widespread in different specific problems. Now it is time to summarize a bit and form a reference document as a reminder for myself. And this document is continually updated as other ones in this series.
<!---
During the past summer I tried my best to find as more meaningful modules in weighted networks, which is comptationally intensive. See the [challenge](https://www.synapse.org/#!Synapse:syn6156761/wiki/400645) and our [solution](https://www.synapse.org/#!Synapse:syn7136340/wiki/403063). It turned out that the optimization based approach runs slowly even on High Performance Computers such as [Bluebear](https://intranet.birmingham.ac.uk/it/teams/infrastructure/research/bear/index.aspx). Speed has become important enough to affect the prograss. After the challenge I rewrote the core part of that algorithm in C and got 10x speedup. The topic is how to make the program more efficient.
-->

# Preparing

In order to know the exact running time (cpu time) of a piece of code, we need the following system functions:

### R
```{r,eval=FALSE}
ptm <- proc.time(); {your code}; proc.time() - ptm
```

### Matlab
```
tic; {your code}; toc
```

### Python
```
import time
start_time = time.clock()
# your code
print time.clock() - start_time, "seconds"
```

### C
```
#include <time.h>
clock_t tic = clock();
// your code
cpu_time_used = (double)(clock() - tic) / CLOCKS_PER_SEC
```

### Java
```
long startTime = System.currentTimeMillis();
// your code
long totalTime = System.currentTimeMillis() - startTime;
```

Find the bottleneck piece first, then try to optimize it!

# Language choice

It is a trade-off between efficiency and easy-to-use. Machine code is the most efficient language but probably no one really want to use it. Assembly is also efficient and close to processor instructions still few want to try nowadays. They are difficult to understand for most people. Most popular languages are close to human, some of them are popular among scholars just because of easy-to-use. Both Matlab and R allow us to write code just like deriving equations. The cost is efficiency, especially when involving many direct operations on matrices and vectors. 

A reasonable choice is to combine both low-level languages like C/C++ and high-level scripts as Matlab/R. Take computational biology for example, R has been quite popular among biostatisticians/biologists for historical reasons, and many important databases are easily accessed by R packages. We can use R to do high-level but not computational intensive jobs: data access, preprocessing, basic statisitics analaysis, files manipulation, visualization (much easier with R) ..., and leave the bottleneck jobs such as numerical optimization for C/C++. We followed this principle in the package [AMOUNTAIN](https://github.com/fairmiracle/AMOUNTAIN) in which the C-version functions are faster 10x than pure R.

# Always use libraries

<span style="color:red">**Just because thay are faster than what you write**!</span>

Even in high efficient languages in C, it is always better to use a popular library for some calculation than implementing by yourself. Take the linear algebra operations for example, the well known Basic Linear Algebra Subprograms (BLAS) are the *de facto* standard low-level routines which is much more efficient than explicit implementation. One of the multiple choices of BLAS implementations is the [GNU Scientific Library (GSL)](https://www.gnu.org/software/gsl), which provides common numerical libraries for C and C++ programmers.

Take a simple Matrix-Vector Multiplication for example. Given a matrix $A\in \mathbb{R}^{n\times n}$ and a vector ${\bf x}\in \mathbb{R}^n$, calculate ${\bf y}=A{\bf x}$. The explicit implementation is based on the fact that $y_i=\sum_{j}A_{ij}x_j$, the C code may look like:

```
void mydgemv(double *A, double *x, double *y, int m, int n){
	for (int i = 0; i < m; ++i)
	{
		double rowSum = 0;
		for (int j = 0; j < n; ++j)
		{
			rowSum += A[i+j*n]*x[j];
		}
		y[i] = rowSum;
	}
}
mydgemv(A, x, y1, n, n);
```

It is also straightforward to call BLAS as
```
cblas_dgemv(CblasColMajor, CblasNoTrans, n, n, 1, A, n, x, 1, 0, y2, 1);
```

If we measure the CPU time, the difference between two methods is obvious when the matrix is large. When n=10000, the output is:
```
Naive cpu time: 7.083000
CBLAS cpu time: 0.234000
MSE ||y1-y2||^2 between two methods: 0.000000
```

Click [here](useBLAS.c) for full code, and to view as syntax-highlighted  [HTML](useBLAS.html).


A nice summary of commonly used math libraries can be find at [Math Libraries](https://www.chpc.utah.edu/documentation/software/mathlibraries.php). The best way to study a specific library is to use it!

# Use sparse matrices if possible

sparse representation outperforms dense representation from two aspects: speed and memory. If the matrix itself is sparse, do not forget the corresponding libraries. 
In Matlab try the following Matrix-Vector Multiplication:
```
n=10000;
A = sprand(n,n,0.01);
x = rand(n,1);
tic; y1=A*x; toc
B=full(A);
tic; y2=B*x; toc
norm(y1-y2)
```


# Vectorization

Almost every tutorial on Matlab or R mentioned the importance of vectorization. The principle is to avoid explicit for-loops if possible. 

### Explicit vectorization design 
Still on Matrix-Vector Multiplication, compare the following two ways:
```
n=10000;
A = sprand(n,n,0.01);
x = rand(n,1);
y1 = zeros(n,1);
tic
for i=1:n
  for j=1:n
    y1(i) = y1(i) + A(i,j) * x(j);
  end
end
toc
tic; y2=A*x; toc
norm(y1-y2)
```

But sometimes vectorization can be tricky.
http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial
https://www.mathworks.com/help/matlab/matlab_prog/techniques-for-improving-performance.html

### Specified functions
bxfun for Matlab,
apply, sapply, lapply in R
In R even `i in 1:n` is suggested to be replaced as `i in seq_len(v)`
# Better design of logic

Sometimes it needs more considerations on trivial numerical 
A good reference for the course by CJ Lin: [Numerical Methods](https://www.csie.ntu.edu.tw/~cjlin/courses/nm2016/)

# Hardware considerations
GPU
Cluster
All above discussions are about running program on single machines. When dealing with big data, parallel and distributed computing almost becomes the only choice. 

# Reference
Blog 1: [Faster R: Things to not forget](http://pj.freefaculty.org/blog/?p=122)

[UFLDL Tutorial](http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial)

https://www.mathworks.com/help/matlab/matlab_prog/techniques-for-improving-performance.html